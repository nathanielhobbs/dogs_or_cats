{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nathan's Kaggle Dogs vs Cats Redux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebooks will:\n",
    "\n",
    "0. Introduce one way to pull data from kaggle\n",
    "1. Create directory structure for utilities, vgg, and data (training, validation, sample, and test)\n",
    "2. Download and unzip necessary data from Kaggle\n",
    "3. Set up VGG to analyze training images and build model\n",
    "4. Finetune the model to categorize just dogs and cats\n",
    "5. Submit results to Kaggle via Kaggle CLI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading kaggle data\n",
    "\n",
    "While a client for downloading kaggle exists, [kaggle-cli](https://github.com/floydwch/kaggle-cli), I had trouble with it.  \n",
    "\n",
    "Instead I logged into Kaggle in Chrome and [copied the curl request](https://coderwall.com/p/-fdgoq/chrome-developer-tools-adds-copy-as-curl), then pasted that into the command line followed by -o filename.zip to make sure the output was to a file and not to STDOUT.\n",
    "\n",
    "After dowloading both train.zip and test.zip, I unzipped the contents into the /data/redux/ directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Double Check Directory Structure\n",
    "\n",
    "For now, we should have a directory structure that looks like this:\n",
    "\n",
    "```\n",
    "utils/\n",
    "    vgg16.py                        // from fast.ai, this is the algorithm for image classification\n",
    "    utils.py                        // from fast.ai, this is a collection of functions\n",
    "lesson1/\n",
    "    nathan_dogs_cats_redux.ipynb    // this file\n",
    "    lesson1.ipynb                   // from fast.ai, this is a notebook that describes how to use vgg16\n",
    "    data/\n",
    "        redux/                      // kaggle data will be put into this dir and unzipped into train/ and test/\n",
    "            train/\n",
    "                cat.348.jpg\n",
    "                dog.3778.jpg\n",
    "                ...\n",
    "            test/\n",
    "                123.jpg\n",
    "                857.jpg\n",
    "                ...\n",
    "```                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'/home/ubuntu/nbs/lesson1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check to make sure we are in the right directory (/home/ubuntu/nbs/lesson1/)\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# allow plots to show up in this notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create references to directories we will use often\n",
    "import os, sys\n",
    "current_dir = os.getcwd()\n",
    "HOME_DIR_LESSON = current_dir\n",
    "HOME_DIR_DATA = current_dir+'/data/redux'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaggle zips found, assuming they've been unzipped appropriately\n"
     ]
    }
   ],
   "source": [
    "# download kaggle data and unzip if this hasn't been done before\n",
    "if os.path.isfile(HOME_DIR_DATA+'/train.zip') == False:\n",
    "    print(\"No Kaggle Training zip found, double check you have training data\")\n",
    "elif os.path.isfile(HOME_DIR_DATA+'/test.zip') == False:\n",
    "    print(\"No Kaggle Testing zip found, double check you have test data\")\n",
    "else:\n",
    "    print(\"Kaggle zips found, assuming they've been unzipped appropriately\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Allow relative imports to directories above lesson1/\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slice up Kaggle Data for training\n",
    "\n",
    "Now we're going to slice up the Kaggle data into further pieces, e.g the training set will be broken up into 3 subsets: train, validate, and sample.  We will create new directories and move around Kaggle data appropriately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1. Create proper directory structure\n",
    "\n",
    "```\n",
    "utils/\n",
    "lesson1/\n",
    "    data/\n",
    "        redux/                       \n",
    "            train/\n",
    "            test/\n",
    "                *unknown/\n",
    "            *valid/\n",
    "            *results/\n",
    "            *sample/\n",
    "                *train/\n",
    "                *test/\n",
    "                *valid/\n",
    "                *results/\n",
    "            \n",
    "        \n",
    "```         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/nbs/lesson1/data/redux\n"
     ]
    }
   ],
   "source": [
    "# Create directories if they don't exist\n",
    "%cd $HOME_DIR_DATA\n",
    "\n",
    "if os.path.exists(HOME_DIR_DATA+'/valid') == False:\n",
    "    %mkdir valid\n",
    "if os.path.exists(HOME_DIR_DATA+'/results') == False:\n",
    "    %mkdir results\n",
    "if os.path.exists(HOME_DIR_DATA+'/sample/train') == False:\n",
    "    %mkdir -p sample/train\n",
    "if os.path.exists(HOME_DIR_DATA+'/sample/test') == False:\n",
    "    %mkdir -p sample/test\n",
    "if os.path.exists(HOME_DIR_DATA+'/sample/valid') == False:\n",
    "    %mkdir -p sample/valid\n",
    "if os.path.exists(HOME_DIR_DATA+'/sample/results') == False:\n",
    "    %mkdir -p sample/results\n",
    "if os.path.exists(HOME_DIR_DATA+'/test/unkonwn') == False:\n",
    "    %mkdir -p test/unknown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Break up Kaggle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/nbs/lesson1/data/redux/train\n"
     ]
    }
   ],
   "source": [
    "%cd $HOME_DIR_DATA/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import glob module for finding pathnames (note: results in arbitrary order)\n",
    "import glob \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get all training data and shuffle it before breaking it up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000 : total training files\n"
     ]
    }
   ],
   "source": [
    "# get array of all files in training set\n",
    "training_pics = glob.glob('*.jpg')\n",
    "# permute them for randomization\n",
    "shuf = np.random.permutation(training_pics)\n",
    "train_set_size = len(shuf)\n",
    "print train_set_size,': total training files'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Seperate* Data For Validation Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Separate (i.e. move) 10% of original training data off for validation set.  This shouldn't be done more than once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "valid_set_size = int(train_set_size*0.1)\n",
    "if len(os.listdir(HOME_DIR_DATA+'/valid/')) == 0:\n",
    "    for i in range(valid_set_size):\n",
    "        os.rename(shuf[i], HOME_DIR_DATA+'/valid/' + shuf[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Copy* Data For Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Copy ~1% subset of remaining training data for sampling (i.e. training on very small dataset for speed considerations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get array of remaining files after splitting off validation set\n",
    "training_pics_sub_val = glob.glob('*.jpg')\n",
    "shuf = np.random.permutation(training_pics_sub_val)\n",
    "sample_test_size = int(len(shuf)*0.01)\n",
    "if len(os.listdir(HOME_DIR_DATA+'/sample/train/')) == 0:\n",
    "    for i in range(sample_test_size):\n",
    "        copyfile(shuf[i], HOME_DIR_DATA+'/sample/train/'+shuf[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Copy ~2% subset of seperated validation data for sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/nbs/lesson1/data/redux/valid\n"
     ]
    }
   ],
   "source": [
    "%cd $HOME_DIR_DATA/valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/sample/valid is empty\n"
     ]
    }
   ],
   "source": [
    "if len(os.listdir(HOME_DIR_DATA+'/sample/valid/')) == 0:\n",
    "    print('/sample/valid is empty')\n",
    "    validation_set = glob.glob(\"*.jpg\")\n",
    "    shuf = np.random.permutation(validation_set)\n",
    "    sample_valid_size = int(len(shuf)*0.02)\n",
    "    for i in range(sample_valid_size):\n",
    "        copyfile(shuf[i], HOME_DIR_DATA+'/sample/valid/'+shuf[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Break up* Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/nbs/lesson1/data/redux/sample/train\n"
     ]
    }
   ],
   "source": [
    "%cd $HOME_DIR_DATA/sample/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.isdir(HOME_DIR_DATA+'/sample/train/dogs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/nbs/lesson1/data/redux/sample/train\n"
     ]
    }
   ],
   "source": [
    "# Divide sample train cat/dog images into seperate directories\n",
    "\n",
    "%cd $HOME_DIR_DATA/sample/train\n",
    "if os.path.isdir(HOME_DIR_DATA+'/sample/train/dogs') == False:\n",
    "    %mkdir dogs\n",
    "    %mv dog.*.jpg dogs/\n",
    "if os.path.isdir(HOME_DIR_DATA+'/sample/train/cats') == False:\n",
    "    %mkdir cats\n",
    "    %mv cat.*.jpg cats/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/nbs/lesson1/data/redux/sample/valid\n"
     ]
    }
   ],
   "source": [
    "# Divide sample valid cat/dog images into seperate directories\n",
    "\n",
    "%cd $HOME_DIR_DATA/sample/valid\n",
    "if os.path.isdir(HOME_DIR_DATA+'/sample/valid/dogs') == False:\n",
    "    %mkdir dogs\n",
    "    %mv dog.*.jpg dogs/\n",
    "if os.path.isdir(HOME_DIR_DATA+'/sample/valid/cats') == False:\n",
    "    %mkdir cats\n",
    "    %mv cat.*.jpg cats/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/nbs/lesson1/data/redux/train\n"
     ]
    }
   ],
   "source": [
    "# Divide training set cat/dog images into seperate directories\n",
    "\n",
    "%cd $HOME_DIR_DATA/train\n",
    "if os.path.isdir(HOME_DIR_DATA+'/train/dogs') == False:\n",
    "    %mkdir dogs\n",
    "    %mv dog.*.jpg dogs/\n",
    "if os.path.isdir(HOME_DIR_DATA+'/train/cats') == False:\n",
    "    %mkdir cats\n",
    "    %mv cat.*.jpg cats/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/nbs/lesson1/data/redux/valid\n"
     ]
    }
   ],
   "source": [
    "# Divide validation set cat/dog images into seperate directories\n",
    "\n",
    "%cd $HOME_DIR_DATA/valid\n",
    "if os.path.isdir(HOME_DIR_DATA+'/valid/dogs') == False:\n",
    "    %mkdir dogs\n",
    "    %mv dog.*.jpg dogs/\n",
    "if os.path.isdir(HOME_DIR_DATA+'/valid/cats') == False:\n",
    "    %mkdir cats\n",
    "    %mv cat.*.jpg cats/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create single 'unknown' class for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/nbs/lesson1/data/redux/test\n"
     ]
    }
   ],
   "source": [
    "%cd $HOME_DIR_DATA/test\n",
    "%mv *.jpg unknown/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train First Generation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/nbs/lesson1\n"
     ]
    }
   ],
   "source": [
    "# import modules\n",
    "%cd $HOME_DIR_LESSON\n",
    "from utils import utils\n",
    "from utils.vgg16 import Vgg16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We use vgg16, an existing image classifier which classifies images into one of 1000 different categories found on imagenet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/nbs/lesson1/data/redux\n"
     ]
    }
   ],
   "source": [
    "%cd $HOME_DIR_DATA\n",
    "\n",
    "# set paths for training set (can take away sample/ once evertyhing's working)\n",
    "path = HOME_DIR_DATA + '/sample/' #'/' for whole dataset\n",
    "test_path = path + 'test/'\n",
    "results_path = path + 'results/'\n",
    "train_path = path + 'train/'\n",
    "valid_path = path + 'valid/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set Vgg16 helper class from vgg16 library\n",
    "vgg = Vgg16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set constants: \n",
    "# batch size usu. recommended to be no larger than 64, can adjust\n",
    "# to be smaller if running out of memory\n",
    "batch_size = 64\n",
    "# Increasing no_of_epochs should improve accuracy\n",
    "no_of_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 225 images belonging to 2 classes.\n",
      "Found 50 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# grab a few images at a time for training and validation. \n",
    "# a batch is a collection of images and labels from \n",
    "batches = vgg.get_batches(train_path, batch_size=batch_size)\n",
    "val_batches = vgg.get_batches(valid_path, batch_size=batch_size*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's see what we have so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
